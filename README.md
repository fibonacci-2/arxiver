# Paper Producer ğŸ“„

**Advanced RAG system for generating comprehensive research reports from ArXiv papers with an intelligent web interface.**

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

## ğŸ¯ Features

### Core Capabilities
- **ğŸ¤– Two-Level Query Processing**: Natural language input â†’ LLM analyzes requirements â†’ Optimized ArXiv search
- **ğŸ” Multi-Paper Synthesis**: Retrieval-Augmented Generation across 20+ papers simultaneously
- **ğŸ“Š 4 Indexer Options**: Vector (semantic), BM25 (probabilistic), TF-IDF (statistical), Inverted (keyword)
- **ğŸ“‘ Academic LaTeX Output**: Professional reports with citations, bibliography, and abstract
- **ğŸ¨ Clean Web UI**: Three-column layout with real-time progress tracking and PDF preview
- **âš™ï¸ Configurable Pipeline**: YAML-based configuration with runtime parameter override

### Advanced Features
- **Smart Paper Ranking**: Embedding-based relevance scoring
- **Incremental Progress Display**: Real-time paper fetching and processing logs
- **Graceful Error Handling**: Continues on individual paper failures
- **Citation Management**: Automatic `\cite{}` insertion and bibliography generation
- **ArXiv ID Normalization**: Handles all formats (versioned, categorized, modern)

---

## ğŸ“ System Overview

![System Architecture](system-overview.pdf)

[ğŸ“„ View Full System Overview (PDF)](./system-overview.pdf)

### Pipeline Flow

```
User Query (Natural Language)
    â†“
[1. Query Processor] â†’ LLM analyzes â†’ Structured JSON spec
    â†“
[2. Searcher] â†’ ArXiv API â†’ Papers with metadata
    â†“
[2. Ranker] â†’ Embedding similarity â†’ Top 20 papers
    â†“
[3. Fetcher] â†’ Download PDFs â†’ Local storage
    â†“
[3. Extractor] â†’ PyPDF2 â†’ Full text + metadata
    â†“
[4. Indexer] â†’ Chunk + Index â†’ Retrieval database
    â†“
[4. RAG Retrieval] â†’ Top 10 relevant chunks â†’ LLM context
    â†“
[4. Synthesizer] â†’ LLM generation â†’ LaTeX report
    â†“
[5. Report Generator] â†’ pdflatex â†’ Final PDF
    â†“
Preview + Download
```

**Configuration drives all stages:**
```yaml
embeddings: text-embedding-3-small
indexer: vector/bm25/tfidf/inverted
llm: gpt-4o-mini (temp: 0)
search: max=10, top_papers=20
chunks: size=1000, overlap=200
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.12+
- OpenAI API key
- LaTeX distribution (for PDF compilation)

### Installation

```bash
# Clone repository
git clone https://github.com/fibonacci-2/arxiver.git
cd arxiver

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

### Install LaTeX (for PDF generation)

**Ubuntu/Debian:**
```bash
sudo apt-get install texlive-latex-base texlive-latex-extra
```

**macOS:**
```bash
brew install --cask mactex
```

**Windows:**
Download and install [MiKTeX](https://miktex.org/download)

### Run the Application

```bash
# Start the web server
uvicorn app:app --reload --host 0.0.0.0 --port 8000

# Or use the convenience script
./start.sh
```

Open **http://localhost:8000** in your browser.

---

## ğŸ® Usage

### Web UI (Recommended)

1. **Enter your research requirements** in natural language:
   ```
   "Find recent papers on transformer attention mechanisms, 
   focusing on efficiency improvements and architectural innovations"
   ```

2. **Click "Analyze Query"**: LLM processes your request and shows structured query spec

3. **Click "Generate Report"**: 
   - Searches ArXiv
   - Ranks papers by relevance
   - Downloads and extracts content
   - Generates comprehensive report with citations

4. **Preview and Download**: View report in browser or download PDF

### Configuration Options (Web UI)

- **LLM Model**: `gpt-4o-mini`, `gpt-4o`, `gpt-4-turbo`
- **Indexer Type**: 
  - `vector` - Semantic search (ChromaDB + embeddings)
  - `bm25` - Probabilistic ranking (best for keywords)
  - `tfidf` - Statistical term weighting (fast, local)
  - `inverted` - Classic keyword index
- **Embedding Model**: `text-embedding-3-small`, `text-embedding-3-large`
- **Papers to Fetch**: 10-50 papers (default: 20)

---

## âš™ï¸ Configuration

### Main Config File: `backend/config.yaml`

```yaml
embeddings:
  model: text-embedding-3-small  # or text-embedding-3-large

indexer:
  type: vector                   # vector, bm25, tfidf, inverted
  chunk_size: 1000               # Characters per chunk
  chunk_overlap: 200             # Overlap between chunks
  top_k: 10                      # Chunks to retrieve for LLM context

llm:
  model: gpt-4o-mini             # gpt-4o-mini, gpt-4o, gpt-4-turbo
  temperature: 0                 # 0 = deterministic, 0.7 for query processing

search:
  max_results: 10                # Initial ArXiv search results
  top_papers: 20                 # Papers to process after ranking

output:
  format: latex                  # Output format
```

### Indexer Comparison

| Indexer | Speed | Semantic | Cost | Best For |
|---------|-------|----------|------|----------|
| **vector** | Slow | âœ… Yes | $$ (API) | Natural language queries |
| **bm25** | Fast | âŒ No | Free | Keyword searches |
| **tfidf** | Very Fast | âŒ No | Free | Technical terms, large collections |
| **inverted** | Fastest | âŒ No | Free | Exact term matching |

### Environment Variables: `.env`

```bash
OPENAI_API_KEY=sk-...        # Required: Your OpenAI API key
```

---

## ğŸ“ Project Structure

```
paper-producer/
â”œâ”€â”€ app.py                       # FastAPI application & REST API
â”‚
â”œâ”€â”€ frontend/                    # Web UI (Vanilla JS)
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html          # Three-column layout
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ style.css           # Minimal GitHub-inspired design
â”‚       â””â”€â”€ app.js              # State management & API calls
â”‚
â”œâ”€â”€ backend/                     # Core RAG pipeline
â”‚   â”œâ”€â”€ config.yaml             # System configuration
â”‚   â”œâ”€â”€ config_loader.py        # Singleton config manager
â”‚   â”‚
â”‚   â”œâ”€â”€ query_processor.py      # LLM query analysis
â”‚   â”œâ”€â”€ searcher.py             # ArXiv API client
â”‚   â”œâ”€â”€ ranker.py               # Embedding-based paper ranking
â”‚   â”‚
â”‚   â”œâ”€â”€ fetcher.py              # PDF download from ArXiv
â”‚   â”œâ”€â”€ extractor.py            # Text extraction (PyPDF2)
â”‚   â”‚
â”‚   â”œâ”€â”€ indexers.py             # 4 indexer implementations
â”‚   â”‚   â”œâ”€â”€ VectorIndexer       # ChromaDB + OpenAI embeddings
â”‚   â”‚   â”œâ”€â”€ BM25Indexer         # Okapi BM25 ranking
â”‚   â”‚   â”œâ”€â”€ TFIDFIndexer        # scikit-learn TF-IDF
â”‚   â”‚   â””â”€â”€ InvertedIndexer     # Classic inverted index
â”‚   â”‚
â”‚   â”œâ”€â”€ multi_summarizer.py     # Multi-paper RAG synthesis
â”‚   â”œâ”€â”€ report_generator.py     # LaTeX compilation (pdflatex)
â”‚   â”‚
â”‚   â””â”€â”€ logger.py               # Rich console logging
â”‚
â”œâ”€â”€ data/                        # Generated data (gitignored)
â”‚   â”œâ”€â”€ papers/                 # Downloaded ArXiv PDFs
â”‚   â””â”€â”€ reports/                # Generated report PDFs
â”‚
â”œâ”€â”€ chroma_db_multi/            # ChromaDB vector store (if using vector indexer)
â”‚
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example               # Environment template
â”œâ”€â”€ start.sh                   # Convenience startup script
â””â”€â”€ system-overview.pdf        # Architecture documentation
```

---

## ğŸ”§ API Endpoints

### REST API (FastAPI)

```
GET  /                          Serve web UI
GET  /api/config                Get current configuration
POST /api/config                Update configuration
POST /api/process-query         Analyze user query with LLM
POST /api/generate-advanced     Generate multi-paper report
GET  /api/download/{filename}   Download generated PDF
```

### Example: Process Query

```bash
curl -X POST http://localhost:8000/api/process-query \
  -H "Content-Type: application/json" \
  -d '{"user_input": "Find papers about BERT fine-tuning"}'

# Returns:
{
  "search_query": "BERT fine-tuning transfer learning",
  "themes": ["pre-training", "downstream tasks", "hyperparameters"],
  "structure": ["Introduction", "Methodology", "Results"],
  "special_requirements": "Focus on NLP tasks"
}
```

---

## ğŸ§  How It Works

### Stage 1: Query Intelligence
- User provides natural language requirements
- LLM (gpt-4o-mini, temp=0.7) extracts:
  - Optimized ArXiv search query
  - Research themes to emphasize
  - Report structure
  - Special requirements

### Stage 2: Paper Discovery
- **Search**: ArXiv API with optimized query
- **Rank**: Cosine similarity between query embedding and paper abstracts
- **Select**: Top N papers (configurable, default 20)

### Stage 3: Content Acquisition
- **Fetch**: Download PDFs from ArXiv (parallel with error tracking)
- **Extract**: PyPDF2 extracts text + preserves metadata

### Stage 4: RAG Processing
- **Index**: Text split into chunks (1000 chars, 200 overlap)
- **Retrieve**: Top 10 most relevant chunks across all papers
- **Synthesize**: LLM generates LaTeX report with:
  - Abstract (150-200 words)
  - Structured sections
  - `\cite{paperN}` citations throughout
  - Focus on user-specified themes

### Stage 5: Report Generation
- Wraps content in LaTeX document structure
- Generates `\begin{thebibliography}` with `\bibitem` entries
- Compiles with pdflatex (runs twice for citation resolution)
- Returns PDF + preview text

---

## ğŸ¨ UI Features

- **Three-Column Layout**:
  - Left: Configuration & query input
  - Middle: Papers list & progress logs
  - Right: Report preview with PDF tools
  
- **State Management**:
  - Single button: "Analyze Query" â†’ "Generate Report" â†’ "New Query"
  - Auto-reset on query text change
  
- **Real-Time Updates**:
  - Incremental paper display (100ms fade-in)
  - Detailed progress logging
  - Status indicators

- **Minimal Design System**:
  - GitHub-inspired color palette
  - Consistent 1px borders, 4px radius
  - Clean typography (0.875rem base)

---

## ğŸ› ï¸ Development

### Run in Development Mode

```bash
uvicorn app:app --reload --log-level debug
```

### Project Dependencies

```
fastapi              # Web framework
uvicorn              # ASGI server
langchain            # LLM orchestration
langchain-openai     # OpenAI integration
langchain-community  # ChromaDB integration
chromadb             # Vector database
openai               # OpenAI API client
arxiv                # ArXiv API client
pypdf2               # PDF text extraction
scikit-learn         # TF-IDF vectorization
rank-bm25            # BM25 implementation
pyyaml               # Config management
python-dotenv        # Environment variables
rich                 # Console logging
```

---

## ğŸ“ Examples

### Example Query Inputs

```
"Analyze recent developments in multi-modal transformers 
 with emphasis on vision-language models"

"Find papers about federated learning privacy techniques, 
 comparing differential privacy approaches"

"Survey of graph neural networks for molecular property prediction, 
 focusing on pharmaceutical applications"
```

### Example Output Structure

```latex
\begin{abstract}
This report synthesizes findings from 20 recent papers...
\end{abstract}

\section{Introduction}
Transformers have revolutionized NLP \cite{paper1}...

\section{Methodology Comparison}
Self-attention mechanisms \cite{paper1,paper3} differ from...

\begin{thebibliography}{99}
\bibitem{paper1} Vaswani et al., "Attention Is All You Need", arXiv:1706.03762
\bibitem{paper2} Devlin et al., "BERT: Pre-training...", arXiv:1810.04805
...
\end{thebibliography}
```

---

## ğŸ› Troubleshooting

**LaTeX compilation fails:**
```bash
# Ensure LaTeX is installed
pdflatex --version

# Check logs in data/reports/
```

**ChromaDB errors (vector indexer):**
```bash
# Clear database and rebuild
rm -rf chroma_db_multi/
```

**OpenAI API rate limits:**
- Reduce `top_papers` in config
- Use `tfidf` or `bm25` indexer (no embedding API calls)

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ¤ Contributing

Contributions welcome! Please open an issue or PR.

---

## ğŸ“§ Contact

Project maintained by [fibonacci-2](https://github.com/fibonacci-2)

Repository: [arxiver](https://github.com/fibonacci-2/arxiver)

